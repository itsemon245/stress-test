map $http_upgrade $connection_upgrade {
  default upgrade;
  ''      close;
}

server {

    listen                         *:80;
    listen                      [::]:80;

    include                     /etc/nginx/sites.d/ports_https.conf;
    include                     /etc/nginx/sites.d/ssl_main.conf;
    include                     /etc/nginx/sites.d/ssl_redirect.conf;

    #include                     /etc/nginx/bots.d/blockbots.conf;
    #include                     /etc/nginx/bots.d/ddos.conf;

    ssl_certificate             /etc/letsencrypt/live/dev.artistly.ai/fullchain.pem; # managed by Certbot
    ssl_certificate_key         /etc/letsencrypt/live/dev.artistly.ai/privkey.pem; # managed by Certbot

    server_name                 dev.artistly.ai;

    root                        /var/www/dev.artistly.ai/webroot/public;
    index                       index.php;

    server_tokens               off;
    charset                     utf-8;
    client_body_in_file_only    clean;
    client_body_buffer_size     64K;
    client_max_body_size        2G;
    sendfile                    on;
    send_timeout                60s;

    access_log                  /var/log/nginx/dev.artistly.ai_access.log main;
    error_log                   /var/log/nginx/dev.artistly.ai_error.log  info;

    #Remove in production
    # CRITICAL: Per-IP connection limit for load testing
    # Higher = More connections allowed per IP (needed for multi-connection tests)
    # Lower = Better DDoS protection but blocks legitimate load tests
    # Impact: Too low blocks load tests; too high allows resource exhaustion
    limit_conn perip 500;

    # CRITICAL: Optimized static file serving to prevent client cancellations  
    location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg|woff|woff2)$ {
        # CRITICAL: Aggressive caching to prevent re-downloads in multi-tab testing
        # Higher values = Assets cached longer, fewer requests during load tests
        # Lower values = More server requests but fresher content
        # Impact: Reduces asset requests when opening multiple tabs per Chrome instance
        expires 1y;
        add_header Cache-Control "public, max-age=31536000, immutable";
        add_header Vary Accept-Encoding;
        
        # CRITICAL: Enable ETags for better cache validation
        # Helps browsers determine if cached assets are still valid
        etag on;
        
        # CRITICAL: Enable efficient file sending via kernel 
        # Higher chunk size = Better throughput for large files (like app-BmEEo1fJ.js)
        # Lower chunk size = Better responsiveness for small files
        # Impact: Too low causes poor performance; too high may cause client timeouts
        sendfile on;
        sendfile_max_chunk 5m;  # Increased for heavy concurrent asset loading
        tcp_nopush on;
        tcp_nodelay on;
        
        # CRITICAL: Buffer settings for large JavaScript/CSS files under high load
        # Higher = Better performance for large assets, fewer client cancellations at 250+ connections
        # Lower = More memory efficient but may cause streaming issues
        # Impact: Prevents "client canceled stream" errors during concurrent asset loading
        output_buffers 4 128k;  # Doubled for high concurrent asset requests
        postpone_output 1460;
        
        # CRITICAL: Optimizations for concurrent asset serving
        # Higher values = Better performance under load but more resource usage
        # Lower values = More efficient but may cause timeouts at 250+ connections
        # Impact: Reduces asset serving bottleneck discovered at 250 connections
        open_file_cache_errors off;  # Don't cache 404s for static files
        aio threads;  # Use thread pool for file I/O (better for concurrent requests)
        directio 4m;  # Use direct I/O for large files (reduces memory pressure)
    }

    location / {
        try_files              $uri $uri/ /index.php?$query_string;
    }

    # CRITICAL: Proxy configuration for WebSocket/Reverb connections
    location /app {
            proxy_pass http://127.0.0.1:7001;

            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection $connection_upgrade;
            proxy_set_header Host $host;
            # carry over IP/auth if you use private channels
            proxy_set_header X-Real-IP      $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header Cookie         $http_cookie;
            proxy_set_header Authorization  $http_authorization;
            proxy_set_header Origin         $http_origin;

            # CRITICAL: Proxy buffering for WebSocket events  
            # Off = Better for real-time but may cause memory pressure with large payloads
            # On = Better for large event payloads but slightly higher latency
            # Impact: Large WebSocket events at 178+ connections need buffering optimization
            proxy_buffering    off;
            
            # CRITICAL: Buffer sizes for large WebSocket event payloads
            # Higher = Handle larger events in memory, prevent disk buffering
            # Lower = More memory efficient but may cause temporary file usage
            # Impact: Prevents "buffered to temporary file" at high connection counts
            proxy_buffer_size       128k;
            proxy_buffers           8 128k;
            proxy_busy_buffers_size 256k;

            # CRITICAL: Connection establishment timeout
            # Higher = More tolerance for slow backend startup/high load
            # Lower = Faster failure detection, but may timeout legitimate slow connections
            # Impact: Too low causes "upstream timed out" errors; too high masks real problems
            proxy_connect_timeout 60s;
            
            # CRITICAL: WebSocket connection read timeout (long-lived connections)
            # Higher = Allows longer periods of WebSocket inactivity
            # Lower = May close legitimate long-running WebSocket connections
            # Impact: Too low kills active WebSocket sessions; too high wastes server resources
            proxy_read_timeout 1800s;
            
            # CRITICAL: WebSocket connection send timeout
            # Higher = More tolerance for slow client connections
            # Lower = Faster cleanup of stalled connections
            # Impact: Too low drops slow clients; too high allows resource exhaustion
            proxy_send_timeout 1800s;
    }

    location  ~ \.php$ {
        try_files                           $uri =404;
        expires                             off;
        fastcgi_read_timeout                120;
        fastcgi_pass                        unix:/var/run/php/php8.3-fpm_dev.artistly.ai.sock;
        fastcgi_keep_conn                   on;
        include                             fastcgi_params;
        fastcgi_param                       HTTPS on;
        fastcgi_param                       REQUEST_SCHEME https;
        fastcgi_param                       SCRIPT_FILENAME $document_root${fastcgi_script_name};
    }

}
